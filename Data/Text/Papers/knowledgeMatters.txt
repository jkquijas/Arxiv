We explored the effect of introducing prior knowledge into the intermediate level of deep
supervised neural networks on two tasks. On a task we designed, all black-box state-of-the-art machine learning
algorithms which we tested, failed to generalize well. We motivate our work from the hypothesis that, there is a
training barrier involved in the nature of such tasks, and that humans learn useful intermediate concepts from
other individuals by using a form of supervision or guidance using a curriculum. Our results provide a positive
evidence in favor of this hypothesis. In our experiments, we trained a two-tiered MLP architecture on a dataset
for which each input image contains three sprites, and the binary target class is 1 if all of three
shapes belong to the same category and otherwise the class is 0. In terms of generalization,
black-box machine learning algorithms could not perform better than chance on this task.
Standard deep supervised neural networks also failed to generalize. However, using a particular
structure and guiding the learner by providing intermediate targets in the form of intermediate
concepts (the presence of each object) allowed us to solve the task efficiently. We obtained much
better than chance, but imperfect results by exploring different architectures and optimization
variants. This observation might be an indication of optimization difficulty when the neural
network trained without hints on this task. We hypothesize that the learning difficulty is due
to the composition of two highly non-linear tasks. Our findings are also consistent with the
hypotheses on cultural learning inspired by the observations of training of neural networks
sometimes getting stuck, even though good solutions exist, both in terms of training and
generalization error.

deep learning, neural networks, optimization, evolution of culture, curriculum
learning, training with hints
